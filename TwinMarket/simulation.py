"""
äº¤æ˜“æ¨¡æ‹Ÿç³»ç»Ÿä¸»ç¨‹åº


è¯¥æ¨¡å—è´Ÿè´£è¿è¡Œå®Œæ•´çš„è‚¡ç¥¨äº¤æ˜“æ¨¡æ‹Ÿï¼ŒåŒ…æ‹¬ç”¨æˆ·è¡Œä¸ºã€è®ºå›äº’åŠ¨ã€äº¤æ˜“æ‰§è¡Œç­‰ã€‚
"""

# æ ‡å‡†åº“å¯¼å…¥
import argparse
import asyncio
import json
import logging
import math
import os
import random
import sqlite3
import threading
from contextlib import closing
from datetime import datetime, timedelta
from typing import Dict, Literal, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
import pandas as pd
import yaml
from openai import OpenAI
from tqdm import tqdm

# æœ¬åœ°æ¨¡å—å¯¼å…¥
import trader.trading_agent as TradingAgent
from Agent import BaseAgent
from trader.matching_engine import test_matching_system, update_profiles_table_holiday
from trader.utility import init_system
from util.UserDB import (
    get_all_user_ids,
    get_user_profile,
    build_graph,
    load_graph,
    update_graph,
    save_graph,
    build_graph_new,
    get_top_n_users_by_degree,
)
from util.ForumDB import (
    init_db_forum,
    execute_forum_actions,
    update_posts_score_by_date,
    update_posts_score_by_date_range,
    create_post_db,
    get_all_users_posts_db,
)

# ============================ å…¨å±€é…ç½®å¸¸é‡ ============================
# ä»£ç†æ¿€æ´»æ¦‚ç‡ï¼ˆé»˜è®¤å…¨éƒ¨æ¿€æ´»ï¼‰
ACTIVATE_AGENT_PROB = 1

# è¶…æ—¶é˜ˆå€¼ï¼ˆç§’ï¼‰- 5åˆ†é’Ÿ
TIMEOUT_THRESHOLD = 5 * 60

# é…ç½®æ—¥å¿—è¾“å‡ºæ ¼å¼
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)

# çº¿ç¨‹é”ï¼Œç”¨äºä¿æŠ¤å¹¶å‘æ–‡ä»¶å†™å…¥æ“ä½œ
lock = threading.Lock()


def process_user_input(
    user_id,
    user_db,
    forum_db,
    df_stock,
    current_date,
    debug,
    day_1st,
    current_user_graph,
    import_news,
    df_strategy,
    is_trading_day,
    top_user,
    log_dir,
    prob_of_technical,
    user_config_mapping,
    activate_maapping,
    belief_args,
    config_path,
):
    """
    å¤„ç†å•ä¸ªç”¨æˆ·çš„äº¤æ˜“è¾“å…¥å’Œå†³ç­–è¿‡ç¨‹

    Args:
        user_id: ç”¨æˆ·ID
        user_db: ç”¨æˆ·æ•°æ®åº“è·¯å¾„
        forum_db: è®ºå›æ•°æ®åº“è·¯å¾„
        df_stock: è‚¡ç¥¨æ•°æ® DataFrame
        current_date: å½“å‰æ—¥æœŸ
        debug: æ˜¯å¦å¼€å¯è°ƒè¯•æ¨¡å¼
        day_1st: æ˜¯å¦ä¸ºç¬¬ä¸€å¤©
        current_user_graph: å½“å‰ç”¨æˆ·å…³ç³»å›¾
        import_news: å¯¼å…¥çš„æ–°é—»æ•°æ®
        df_strategy: ç”¨æˆ·ç­–ç•¥æ•°æ®
        is_trading_day: æ˜¯å¦ä¸ºäº¤æ˜“æ—¥
        top_user: é¡¶çº§ç”¨æˆ·åˆ—è¡¨
        log_dir: æ—¥å¿—ç›®å½•
        prob_of_technical: æŠ€æœ¯é¢äº¤æ˜“è€…æ¦‚ç‡
        user_config_mapping: ç”¨æˆ·é…ç½®æ˜ å°„
        activate_maapping: ç”¨æˆ·æ¿€æ´»æ˜ å°„
        belief_args: ä¿¡å¿µå€¼å‚æ•°
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„

    Returns:
        tuple: (user_id, forum_args, decision_result, post_response_args)
    """
    try:
        # è·å–ç”¨æˆ·äº¤æ˜“ç­–ç•¥
        user_strategy = df_strategy[df_strategy["user_id"] == user_id].iloc[0][
            "strategy"
        ]
        # åˆ¤æ–­æ˜¯å¦ä¸ºéšæœºæŠ€æœ¯é¢äº¤æ˜“è€…ï¼ˆéé¡¶çº§ç”¨æˆ·ä¸”äº¤æ˜“æ—¥ä¸”ç¬¦åˆæ¦‚ç‡ï¼‰
        is_random_trader = (
            user_strategy == "æŠ€æœ¯é¢"
            and user_id not in top_user
            and is_trading_day
            and random.random() < prob_of_technical
        )

        # è·å–ç”¨æˆ·å†å²ä¿¡æ¯
        # å¦‚æœæ˜¯ç¬¬ä¸€å¤©ï¼Œä» Profiles è¡¨è·å–æœ€æ–°çš„ç”¨æˆ·ä¿¡æ¯ï¼ˆä¸ä¾èµ– created_atï¼‰
        if day_1st:
            user_profile = get_user_profile(
                db_path=user_db, user_id=user_id, created_at=None
            )
        else:
            # éç¬¬ä¸€å¤©ï¼šä½¿ç”¨å‰ä¸€å¤©çš„æ•°æ®
            profile_date = current_date - timedelta(days=1)
            profile_date_str = profile_date.strftime("%Y-%m-%d 00:00:00")
            user_profile = get_user_profile(
                db_path=user_db, user_id=user_id, created_at=profile_date_str
            )
            # å¦‚æœè·å–å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å½“å‰æ—¥æœŸ
            if not user_profile:
                current_date_str = current_date.strftime("%Y-%m-%d 00:00:00")
                user_profile = get_user_profile(
                    db_path=user_db, user_id=user_id, created_at=current_date_str
                )
            # å¦‚æœä»ç„¶å¤±è´¥ï¼Œè·å–æœ€æ–°çš„è®°å½•
            if not user_profile:
                user_profile = get_user_profile(
                    db_path=user_db, user_id=user_id, created_at=None
                )
        
        # æœ€åæ£€æŸ¥ï¼šç¡®ä¿è‡³å°‘åŒ…å«å¿…éœ€çš„å­—æ®µ
        if not user_profile:
            user_profile = {}
        
        # ç¡®ä¿åŒ…å«æ‰€æœ‰å¿…éœ€çš„å­—æ®µ
        if "user_id" not in user_profile:
            user_profile["user_id"] = str(user_id)
        if "cur_positions" not in user_profile or user_profile.get("cur_positions") is None:
            user_profile["cur_positions"] = {}
        if "current_cash" not in user_profile or user_profile.get("current_cash") is None:
            user_profile["current_cash"] = user_profile.get("ini_cash", 0)
        if "total_value" not in user_profile or user_profile.get("total_value") is None:
            user_profile["total_value"] = user_profile.get("current_cash", 0)
        if "return_rate" not in user_profile or user_profile.get("return_rate") is None:
            user_profile["return_rate"] = 0
        if "total_return" not in user_profile or user_profile.get("total_return") is None:
            user_profile["total_return"] = 0

        # è·å–ç”¨æˆ·å½“å‰æŒä»“è‚¡ç¥¨IDåˆ—è¡¨
        stock_ids = (
            list(user_profile.get("cur_positions", {}).keys())
            if user_profile.get("cur_positions")
            else []
        )
        # è®¾ç½®ç”¨æˆ·çŠ¶æ€æ ‡è¯†
        is_top_user = user_id in top_user
        is_activate_user = activate_maapping[user_id]

        # è·å–ç”¨æˆ·ä¿¡å¿µå€¼ï¼ˆä»ä¸åŒæ•°æ®æºæ ¹æ®æ—¥æœŸè·å–ï¼‰
        try:
            belief = None
            if not day_1st and isinstance(belief_args, dict):
                # éç¬¬ä¸€å¤©ï¼šä»è®ºå›æ•°æ®åº“è·å–ä¿¡å¿µå€¼ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰
                user_posts = belief_args.get(str(user_id))
                if (
                    isinstance(user_posts, list)
                    and len(user_posts) > 0
                    and isinstance(user_posts[0], dict)
                    and "belief" in user_posts[0]
                ):
                    belief = user_posts[0]["belief"]
            elif isinstance(belief_args, pd.DataFrame):
                # ç¬¬ä¸€å¤©æˆ–å¤‡ç”¨æ–¹æ¡ˆï¼šä»CSVæ–‡ä»¶è·å–åˆå§‹ä¿¡å¿µå€¼ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰
                try:
                    user_id_str = str(user_id)
                    # æ£€æŸ¥ belief_args æ˜¯å¦æœ‰ user_id åˆ—
                    if "user_id" in belief_args.columns and "belief" in belief_args.columns:
                        belief_series = belief_args.loc[
                            belief_args["user_id"].astype(str) == user_id_str, "belief"
                        ]
                        belief = belief_series.iloc[0] if not belief_series.empty else None
                    else:
                        belief = None
                except Exception as e:
                    # è°ƒè¯•ä¿¡æ¯ï¼šè¾“å‡ºé”™è¯¯è¯¦æƒ…
                    if debug:
                        print(f"DEBUG: è·å–beliefæ—¶å‡ºé”™ï¼Œuser_id={user_id}, belief_argsç±»å‹={type(belief_args)}, é”™è¯¯={e}")
                    belief = None
            else:
                # belief_args æ—¢ä¸æ˜¯ dict ä¹Ÿä¸æ˜¯ DataFrameï¼Œæ— æ³•è·å– belief
                belief = None
        except Exception as e:
            if debug:
                print(f"è·å–ç”¨æˆ· {user_id} çš„ä¿¡å¿µå€¼æ—¶å‡ºé”™: {e}, belief_argsç±»å‹={type(belief_args)}")
            belief = None

        # æç¤ºæœªèƒ½è·å–åˆ° belief çš„æƒ…å†µ
        # ä»…å¯¹å·²æ¿€æ´»ç”¨æˆ·æç¤ºç¼ºå°‘ beliefï¼›æœªæ¿€æ´»ç”¨æˆ·é™é»˜
        if belief is None and is_activate_user:
            logging.warning(
                f"[belief] ç”¨æˆ· {user_id} æœªèƒ½è·å–åˆ° beliefï¼Œå°†ä»¥ None ç»§ç»­"
            )

        # åˆ›å»ºä¸ªæ€§åŒ–è‚¡ç¥¨äº¤æ˜“ä»£ç†ï¼Œä¼ å…¥ç”¨æˆ·ç›¸å…³ä¿¡æ¯å’Œé…ç½®
        tradingAgent = TradingAgent.PersonalizedStockTrader(
            user_profile=user_profile,  # ç”¨æˆ·èµ„æ–™å’ŒæŒä»“ä¿¡æ¯
            user_graph=current_user_graph,  # ç”¨æˆ·å…³ç³»ç½‘ç»œå›¾
            forum_db_path=forum_db,  # è®ºå›æ•°æ®åº“è·¯å¾„
            user_db_path=user_db,  # ç”¨æˆ·æ•°æ®åº“è·¯å¾„
            df_stock=df_stock,  # è‚¡ç¥¨æ•°æ®
            import_news=import_news,  # å½“æ—¥æ–°é—»ä¿¡æ¯
            user_strategy=user_strategy,  # ç”¨æˆ·äº¤æ˜“ç­–ç•¥
            is_trading_day=is_trading_day,  # æ˜¯å¦äº¤æ˜“æ—¥
            is_top_user=is_top_user,  # æ˜¯å¦ä¸ºé¡¶çº§ç”¨æˆ·
            log_dir=log_dir,  # æ—¥å¿—ç›®å½•
            is_random_trader=is_random_trader,  # æ˜¯å¦ä¸ºéšæœºäº¤æ˜“è€…
            config_path=config_path,  # APIé…ç½®æ–‡ä»¶è·¯å¾„
            is_activate_user=is_activate_user,  # ç”¨æˆ·æ˜¯å¦æ¿€æ´»
            belief=belief,  # ç”¨æˆ·ä¿¡å¿µå€¼
        )

        # è°ƒç”¨äº¤æ˜“ä»£ç†çš„ä¸»è¦å¤„ç†é€»è¾‘ï¼Œè·å–äº¤æ˜“å†³ç­–å’Œè®ºå›äº’åŠ¨ç»“æœ
        (
            forum_args,
            user_id,
            decision_result,
            post_response_args,
            conversation_history,
        ) = tradingAgent.input_info(
            stock_codes=stock_ids,  # ç”¨æˆ·æŒæœ‰çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
            current_date=current_date,  # å½“å‰æ—¥æœŸ
            debug=debug,  # è°ƒè¯•æ¨¡å¼æ ‡è¯†
            day_1st=day_1st,  # æ˜¯å¦ä¸ºç¬¬ä¸€å¤©
        )

        # ä¿å­˜ç”¨æˆ·ä¸AIçš„å¯¹è¯è®°å½•ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        if conversation_history:
            # åˆ›å»ºå¯¹è¯è®°å½•ç›®å½•
            conversation_dir = os.path.join(
                f"{log_dir}/conversation_records/{current_date.strftime('%Y-%m-%d')}"
            )
            os.makedirs(conversation_dir, exist_ok=True)
            conversation_file = os.path.join(conversation_dir, f"{user_id}.json")

            # ä½¿ç”¨çº¿ç¨‹é”ä¿æŠ¤å¹¶å‘æ–‡ä»¶å†™å…¥æ“ä½œ
            with lock:
                with open(conversation_file, "w", encoding="utf-8") as f:
                    json.dump(conversation_history, f, indent=4, ensure_ascii=False)

        # è¿”å›å¤„ç†ç»“æœï¼šç”¨æˆ·IDã€è®ºå›äº’åŠ¨å‚æ•°ã€äº¤æ˜“å†³ç­–ç»“æœã€å¸–å­å›å¤å‚æ•°
        return user_id, forum_args, decision_result, post_response_args

    except Exception as e:
        # å¼‚å¸¸å¤„ç†ï¼šæ‰“å°é”™è¯¯ä¿¡æ¯å¹¶è¿”å›é”™è¯¯çŠ¶æ€
        import traceback
        error_msg = str(e)
        print(f"å¤„ç†ç”¨æˆ· {user_id} æ—¶å‡ºé”™: {error_msg}")
        if debug:
            traceback.print_exc()
        # è¿”å›ç©ºå­—å…¸è€Œä¸æ˜¯åŒ…å«errorçš„å­—å…¸ï¼Œé¿å…ç±»å‹æ··æ·†
        return user_id, [], None, None


def init_simulation(
    start_date: pd.Timestamp = pd.Timestamp("2023-06-15"),
    end_date: pd.Timestamp = pd.Timestamp("2023-06-16"),
    forum_db: str = "data/sample.db",
    user_db: str = "data/sys_100.db",
    debug: bool = True,
    max_workers: int = 1,
    user_graph_save_name: str = "user_graph",
    checkpoint: bool = True,
    similarity_threshold: float = 0.1,
    time_decay_factor: float = 0.05,
    node: int = 1000,
    log_dir: str = "logs",
    prob_of_technical: float = 0.3,
    belief_init_path: str = "util/belief/belief_1000_0129.csv",
    top_n_user: float = 0.1,
    config_path: str = "./config/api.yaml",
    activate_prob: float = 1.0,
):
    """
    åˆå§‹åŒ–å¹¶è¿è¡Œè‚¡ç¥¨äº¤æ˜“æ¨¡æ‹Ÿç³»ç»Ÿ

    è¯¥å‡½æ•°æ˜¯æ•´ä¸ªæ¨¡æ‹Ÿç³»ç»Ÿçš„æ ¸å¿ƒï¼Œè´Ÿè´£åˆå§‹åŒ–æ‰€æœ‰å¿…è¦çš„ç»„ä»¶å¹¶æŒ‰æ—¥æœŸé¡ºåºæ‰§è¡Œæ¨¡æ‹Ÿã€‚

    Args:
        start_date: æ¨¡æ‹Ÿå¼€å§‹æ—¥æœŸ
        end_date: æ¨¡æ‹Ÿç»“æŸæ—¥æœŸ
        forum_db: è®ºå›æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        user_db: ç”¨æˆ·æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        debug: æ˜¯å¦å¼€å¯è°ƒè¯•æ¨¡å¼
        max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°
        user_graph_save_name: ç”¨æˆ·å…³ç³»å›¾ä¿å­˜åç§°
        checkpoint: æ˜¯å¦ä»æ£€æŸ¥ç‚¹å¼€å§‹
        similarity_threshold: ç”¨æˆ·ç›¸ä¼¼åº¦é˜ˆå€¼
        time_decay_factor: æ—¶é—´è¡°å‡å› å­
        node: ç”¨æˆ·èŠ‚ç‚¹æ•°é‡
        log_dir: æ—¥å¿—è¾“å‡ºç›®å½•
        prob_of_technical: æŠ€æœ¯é¢äº¤æ˜“è€…æ¿€æ´»æ¦‚ç‡
        belief_init_path: åˆå§‹ä¿¡å¿µå€¼æ–‡ä»¶è·¯å¾„
        top_n_user: é¡¶çº§ç”¨æˆ·æ¯”ä¾‹
        config_path: APIé…ç½®æ–‡ä»¶è·¯å¾„
        activate_prob: ç”¨æˆ·æ¿€æ´»æ¦‚ç‡
    """
    # ============================ æ¨¡æ‹Ÿåˆå§‹åŒ– ============================
    current_date = start_date

    # æ¸…ç©ºæ•°æ®åº“ä¸­æœªæ¥æ—¥æœŸçš„æ•°æ®ï¼Œç¡®ä¿æ¨¡æ‹Ÿçš„ä¸€è‡´æ€§
    init_system(current_date, user_db, forum_db)

    # åŠ è½½é‡è¦æ–°é—»æ•°æ®ï¼ˆå·²æŒ‰å½±å“åŠ›æ’åºï¼‰
    df_news = pd.read_pickle("data/sorted_impact_news.pkl")
    df_news["cal_date"] = pd.to_datetime(df_news["cal_date"])

    # åŠ è½½äº¤æ˜“æ—¥å†æ•°æ®ï¼Œç”¨äºåˆ¤æ–­å½“æ—¥æ˜¯å¦ä¸ºäº¤æ˜“æ—¥
    df_trading_days = pd.read_csv("data/trading_days.csv")
    df_trading_days["pretrade_date"] = pd.to_datetime(df_trading_days["pretrade_date"])
    trading_days = list(df_trading_days["pretrade_date"].unique())

    # ä»æ•°æ®åº“åŠ è½½ç”¨æˆ·äº¤æ˜“ç­–ç•¥ä¿¡æ¯
    conn = sqlite3.connect(user_db)
    df_strategy = pd.read_sql_query("SELECT * FROM Strategy;", conn)
    df_strategy["user_id"] = df_strategy["user_id"].astype(str)
    conn.close()

    # åŠ è½½ç”¨æˆ·åˆå§‹ä¿¡å¿µå€¼æ•°æ®
    df_init_belief = pd.read_csv(belief_init_path)
    df_init_belief["user_id"] = df_init_belief["user_id"].astype(str)

    # ============================ ä¸»æ¨¡æ‹Ÿå¾ªç¯ ============================
    while current_date <= end_date:

        # åˆ¤æ–­æ˜¯å¦ä¸ºç¬¬ä¸€å¤©ï¼ˆå½±å“æ•°æ®åŠ è½½å’Œåˆå§‹åŒ–é€»è¾‘ï¼‰
        if checkpoint:
            day_1st = False  # ä»æ£€æŸ¥ç‚¹å¼€å§‹ï¼Œä¸æ˜¯ç¬¬ä¸€å¤©
        else:
            day_1st = current_date == start_date  # æ­£å¸¸å¼€å§‹ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºèµ·å§‹æ—¥æœŸ

        # æ£€æŸ¥å½“å‰æ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥
        is_trading_day = current_date in trading_days

        # æ ¹æ®æ˜¯å¦ä¸ºäº¤æ˜“æ—¥åŠ è½½ç›¸åº”çš„è‚¡ç¥¨æ•°æ®
        if is_trading_day:
            # äº¤æ˜“æ—¥ï¼šä»æ•°æ®åº“åŠ è½½è‚¡ç¥¨æ•°æ®
            conn = sqlite3.connect(user_db)
            df_stock = pd.read_sql_query("SELECT * FROM StockData;", conn)
            df_stock["date"] = pd.to_datetime(df_stock["date"])
            conn.close()
        else:
            # éäº¤æ˜“æ—¥ï¼šä¸éœ€è¦è‚¡ç¥¨æ•°æ®
            df_stock = None

        # è·å–å½“æ—¥å¯¹åº”çš„æ–°é—»ä¿¡æ¯
        import_news = df_news[df_news["cal_date"] == current_date].iloc[0]["news"]
        # # è·å–å½“å¤©å¯¹åº”çš„æ–°é—»
        # if not day_1st:
        #     import_news = df_news[df_news['cal_date'] == current_date].iloc[0]['news']
        # else:
        #     # TLEI
        #     import_news = [
        #         'æœ€æ–°å…¬å¸ƒçš„ä¸­å›½åˆ¶é€ ä¸šé‡‡è´­ç»ç†äººæŒ‡æ•°ï¼ˆPMIï¼‰æ•°æ®ä¸ä»…å†æ¬¡ä¸åŠé¢„æœŸï¼Œæ›´å‘ˆç°æ–­å´–å¼ä¸‹è·Œï¼Œè·Œç ´è£æ¯çº¿å¤šä¸ªç™¾åˆ†ç‚¹ã€‚è¿™ä¸ä»…è¯å®äº†åˆ¶é€ ä¸šå¤è‹åŠ¨èƒ½çš„å½»åº•ä¸§å¤±ï¼Œæ›´é‡Šæ”¾äº†ä¸­å›½ç»æµå¯èƒ½åŠ é€Ÿè¿›å…¥è¡°é€€çš„å¼ºçƒˆä¿¡å·ã€‚å¸‚åœºæ‹…å¿§æƒ…ç»ªè”“å»¶ï¼ŒæŠ•èµ„è€…ææ…ŒæŠ›å”®ï¼Œé¢„æœŸç»æµç¡¬ç€é™†çš„é£é™©æ€¥å‰§ä¸Šå‡ã€‚æ›´æœ‰åˆ†æå¸ˆè¡¨ç¤ºï¼Œå½“å‰çš„PMIæ•°æ®åæ˜ çš„å¯èƒ½ä¸æ˜¯ç®€å•çš„å¤è‹ä¹åŠ›ï¼Œè€Œæ˜¯ç»æµç»“æ„çš„æ·±å±‚å´©æºƒã€‚',
        #         'å—ç¾è”å‚¨æŒç»­åŠ æ¯å’Œå…¨çƒé¿é™©æƒ…ç»ªå‡æ¸©å½±å“ï¼Œç¾å…ƒæŒ‡æ•°å¼ºåŠ¿ä¸Šæ¶¨ï¼Œäººæ°‘å¸æ±‡ç‡è¿æ—¥æš´è·Œï¼Œå¼•å‘å¤§è§„æ¨¡èµ„æœ¬å¤–é€ƒæ½®ã€‚å¸‚åœºä¼ è¨€ï¼Œå¤–èµ„æœºæ„æ­£ä»¥æƒŠäººé€Ÿåº¦æŠ›å”®äººæ°‘å¸èµ„äº§ï¼Œå¤§é‡èµ„é‡‘æ¶Œå‘ç¾å…ƒé¿é™©ï¼Œäººæ°‘å¸èµ„äº§ä»·å€¼é¢ä¸´å´©æºƒã€‚æ›´æœ‰åˆ†æå¸ˆè­¦å‘Šï¼Œäººæ°‘å¸è´¬å€¼å¯èƒ½å¼•å‘æ¶æ€§å¾ªç¯ï¼Œè¿›ä¸€æ­¥åŠ å‰§å›½å†…ç»æµä¸‹è¡Œå‹åŠ›ã€‚',
        #         'ç¾å›½æ”¿åºœçªç„¶å®£å¸ƒå¯¹ä¸­å›½è¿›å£å•†å“åŠ å¾æƒ©ç½šæ€§å…³ç¨ï¼Œè´¸æ˜“æˆ˜ä¸ä»…å†æ¬¡å‡çº§ï¼Œæ›´å¯èƒ½æ¼”å˜ä¸ºä¸€åœºå…¨é¢çš„ç»æµå¯¹æŠ—ã€‚æ­¤ä¸¾å°†ä¸¥é‡å†²å‡»ä¸­å›½å¤–è´¸ï¼Œå¯¼è‡´å‡ºå£è®¢å•é”å‡ï¼Œå¤§é‡ä¼ä¸šå€’é—­ï¼Œå¤±ä¸šç‡é£™å‡ã€‚å¸‚åœºæ™®éè®¤ä¸ºï¼Œä¸­ç¾è´¸æ˜“æˆ˜çš„å‡çº§å°†åŠ é€Ÿä¸­å›½ç»æµçš„è¡°é€€è¿›ç¨‹ï¼Œç»æµå¯’å†¬å¯èƒ½æå‰æ¥ä¸´ã€‚æŠ•èµ„è€…ææ…Œæƒ…ç»ªæ€¥å‰§å‡æ¸©ï¼ŒAè‚¡å¸‚åœºæŠ›å”®æ½®ä¸æ–­ã€‚'
        #         'å…¨çƒè´¸æ˜“èç¼©åŠ å‰§ï¼Œèˆªè¿ä¸šé­å—å²æ— å‰ä¾‹çš„é‡åˆ›ï¼Œä½œä¸ºè¡Œä¸šé¾™å¤´çš„ä¸­å›½è¿œæ´‹æµ·è¿é›†å›¢ï¼ˆä¸­è¿œæµ·æ§SH601919ï¼‰ä¹Ÿé¢ä¸´ç ´äº§é£é™©ã€‚å¸‚åœºä¼ è¨€ï¼Œå…¬å¸å€ºåŠ¡ç¼ èº«ï¼Œèµ„äº§è´Ÿå€ºè¡¨å½»åº•æ¶åŒ–ï¼Œå³å°†å®£å¸ƒç ´äº§é‡ç»„ï¼Œè‚¡ç¥¨ä»·å€¼å¯èƒ½å½’é›¶ã€‚æ­¤æ¶ˆæ¯ä¸€å‡ºï¼Œæ•´ä¸ªèˆªè¿æ¿å—å“€é¸¿éé‡ï¼Œææ…Œæƒ…ç»ªè¿…é€Ÿè”“å»¶è‡³æ•´ä¸ªAè‚¡å¸‚åœºï¼ŒæŠ•èµ„è€…çº·çº·é€ƒç¦»ã€‚'
        #         'å—ç»æµä¸‹è¡Œå½±å“ï¼Œé«˜ç«¯æ¶ˆè´¹å¸‚åœºå½»åº•å´©å¡Œï¼Œæ›¾ç»è¢«è§†ä¸ºâ€œç¡¬é€šè´§â€çš„è´µå·èŒ…å°ï¼ˆSH600519ï¼‰ç­‰é«˜ç«¯ç™½é…’é”€å”®é¢å¤§å¹…ä¸‹æ»‘ã€‚å¸‚åœºä¼ è¨€ï¼ŒèŒ…å°çš„ç»é”€å•†ä½“ç³»å·²ç»å´©æºƒï¼Œåº“å­˜ç§¯å‹å¦‚å±±ï¼Œå³å°†è¢«è¿«é™ä»·ä¿ƒé”€ã€‚æ›¾ç»é«˜ä¸å¯æ”€çš„â€œèŒ…å°ç¥è¯â€å½»åº•ç ´ç­ï¼Œè‚¡ä»·å¯èƒ½æ–­å´–å¼ä¸‹è·Œï¼Œå¹¶å¼•å‘æ•´ä¸ªæ¶ˆè´¹æ¿å—çš„ææ…Œæ€§æŠ›å”®ã€‚æŠ•èµ„è€…å¯¹ä¸­å›½æ¶ˆè´¹å¸‚åœºå½»åº•å¤±å»ä¿¡å¿ƒã€‚'
        #     ]

        # è¾“å‡ºå½“å‰æ¨¡æ‹Ÿæ—¥æœŸä¿¡æ¯
        print(f"\n=== å½“å‰æ—¥æœŸ: {current_date.strftime('%Y-%m-%d')} ===")
        print(f"äº¤æ˜“æ—¥: {is_trading_day}")

        # è·å–å½“å‰æ—¥æœŸæœ‰æ•ˆçš„æ‰€æœ‰ç”¨æˆ·ID
        all_user = get_all_user_ids(db_path=user_db, timestamp=current_date)

        # config_list = ['./config_random/deepseek_yyz.yaml',
        #                './config_random/deepseek_yyz2.yaml',
        #                './config_random/deepseek_yyz3.yaml',
        #                './config_random/deepseek_yyz4.yaml',
        #                './config_random/deepseek_yyz5.yaml',
        #                './config_random/deepseek_zyf1.yaml',
        #                './config_random/deepseek_zyf2.yaml',
        #                './config_random/deepseek_zyf3.yaml',
        #                './config_random/deepseek_zyf4.yaml',
        #                './config_random/deepseek_wmh.yaml',
        #                './config_random/deepseek_wmh2.yaml',
        #                './config_random/deepseek_wmh3.yaml',
        #                #    './config_random/gaochao_4o.yaml',
        #                #    './config_random/gaochao_4o_mini.yaml'
        #                ]
        # config_prob = [0.12, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08]  # todo

        # ============================ APIé…ç½®ç®¡ç† ============================
        # ä½¿ç”¨å•ä¸€é…ç½®æ–‡ä»¶ï¼ˆå¯æ‰©å±•ä¸ºå¤šä¸ªAPIé…ç½®çš„éšæœºé€‰æ‹©ï¼‰
        config_list = [config_path]
        print(f"ä½¿ç”¨çš„APIé…ç½®: {config_list}")

        # å¤‡æ³¨ï¼šä»¥ä¸‹ä¸ºå…¶ä»–å¯ç”¨çš„APIé…ç½®é€‰é¡¹
        # config_list = ['./config_random/zyf.yaml']                    # è‡ªå®šä¹‰é…ç½®
        # config_list = ['./config_random/gemini-2.0-flash-exp.yaml']   # Gemini 2.0
        # config_list = ['./config_random/claude_3.5_sonnet.yaml']      # Claude 3.5
        # config_list = ['./config_random/gemini-1.5-flash_latest.yaml'] # Gemini 1.5

        config_prob = [1]  # é…ç½®æ¦‚ç‡æƒé‡ï¼ˆå•ä¸ªé…ç½®æ—¶ä¸º1ï¼‰

        # ä¸ºæ¯ä¸ªç”¨æˆ·éšæœºåˆ†é…APIé…ç½®
        user_config_mapping = {}
        for user_id in all_user:
            # æŒ‰æƒé‡éšæœºé€‰æ‹©é…ç½®æ–‡ä»¶
            selected_config = random.choices(config_list, weights=config_prob, k=1)[0]
            user_config_mapping[user_id] = selected_config

        # ============================ ç”¨æˆ·æ¿€æ´»çŠ¶æ€ç®¡ç† ============================
        # ä¸ºæ¯ä¸ªç”¨æˆ·éšæœºå†³å®šæ˜¯å¦æ¿€æ´»ï¼ˆæ ¹æ®æ¿€æ´»æ¦‚ç‡ï¼‰
        activate_maapping = {}
        for user_id in all_user:
            # æ ¹æ®è®¾å®šçš„æ¿€æ´»æ¦‚ç‡å†³å®šç”¨æˆ·æ˜¯å¦å‚ä¸äº¤æ˜“
            activate = random.random() < activate_prob
            activate_maapping[user_id] = activate

        # ============================ ç”¨æˆ·ä¿¡å¿µå€¼ç®¡ç† ============================
        # æ ¹æ®æ˜¯å¦ä¸ºç¬¬ä¸€å¤©é€‰æ‹©ä¸åŒçš„ä¿¡å¿µå€¼æ•°æ®æº
        belief_args = {}
        if not day_1st:
            # éç¬¬ä¸€å¤©ï¼šä»è®ºå›æ•°æ®åº“è·å–ç”¨æˆ·æœ€æ–°ä¿¡å¿µå€¼
            belief_args = get_all_users_posts_db(
                db_path=forum_db, end_date=current_date
            )
            # ç»Ÿä¸€å­—å…¸ key ä¸ºå­—ç¬¦ä¸²ï¼Œé¿å… int/str ä¸ä¸€è‡´
            if isinstance(belief_args, dict):
                belief_args = {str(k): v for k, v in belief_args.items()}
            else:
                belief_args = {}

            # ä¸ºç¼ºå°‘å¸–å­æˆ–æ—  belief çš„ç”¨æˆ·å›é€€åˆ°åˆå§‹åŒ– belief
            try:
                df_belief = df_init_belief.copy()
                df_belief["user_id"] = df_belief["user_id"].astype(str)
                _fallback_no_post = 0
                _fallback_missing_belief = 0
                for uid in all_user:
                    uid_str = str(uid)
                    posts = belief_args.get(uid_str)
                    if not posts:
                        init_series = df_belief.loc[
                            df_belief["user_id"] == uid_str, "belief"
                        ]
                        if not init_series.empty:
                            belief_args[uid_str] = [{"belief": init_series.iloc[0]}]
                            _fallback_no_post += 1
                    else:
                        # è‹¥å­˜åœ¨å¸–å­ï¼Œä½†é¦–æ¡ç¼ºå°‘ belief å­—æ®µï¼Œäº¦å›é€€
                        if not isinstance(posts[0], dict) or "belief" not in posts[0]:
                            init_series = df_belief.loc[
                                df_belief["user_id"] == uid_str, "belief"
                            ]
                            if not init_series.empty:
                                belief_args[uid_str] = [{"belief": init_series.iloc[0]}]
                                _fallback_missing_belief += 1
                # ä»…è¾“å‡ºä¸€æ¬¡æ±‡æ€»ä¿¡æ¯
                if _fallback_no_post > 0 or _fallback_missing_belief > 0:
                    logging.info(
                        f"[belief] å›é€€æ±‡æ€»ï¼šå½“æ—¥æ— å¸–å­ { _fallback_no_post } äººï¼›å¸–å­ç¼ºå°‘ belief å­—æ®µ { _fallback_missing_belief } äºº"
                    )
            except Exception:
                # å›é€€æ„å»ºå¤±è´¥ä¸è‡´å‘½ï¼Œç»§ç»­ä½¿ç”¨å·²æœ‰çš„ belief_args
                logging.warning(
                    "[belief] æ„å»º belief å›é€€æ˜ å°„æ—¶å‘ç”Ÿå¼‚å¸¸ï¼Œå·²è·³è¿‡å›é€€æ„å»º"
                )
            if isinstance(belief_args, dict):
                # ç»Ÿä¸€ key ä¸ºå­—ç¬¦ä¸²ï¼Œé¿å… int/str ä¸ä¸€è‡´å¯¼è‡´æŸ¥ä¸åˆ°
                belief_args = {str(k): v for k, v in belief_args.items()}
        else:
            # ç¬¬ä¸€å¤©ï¼šä½¿ç”¨åˆå§‹åŒ–çš„ä¿¡å¿µå€¼æ•°æ®
            belief_args = df_init_belief

        # ============================ ç”¨æˆ·å…³ç³»ç½‘ç»œæ„å»º ============================
        # æ„å»ºå½“å‰æ—¥æœŸçš„ç”¨æˆ·å…³ç³»ç½‘ç»œå›¾
        current_user_graph = build_graph_new(
            similarity_threshold=similarity_threshold,  # ç›¸ä¼¼åº¦é˜ˆå€¼
            time_decay_factor=time_decay_factor,  # æ—¶é—´è¡°å‡å› å­
            db_path=user_db,  # ç”¨æˆ·æ•°æ®åº“è·¯å¾„
            start_date="2023-01-01",  # å›¾æ„å»ºèµ·å§‹æ—¥æœŸ
            end_date=current_date.strftime("%Y-%m-%d"),  # å›¾æ„å»ºç»“æŸæ—¥æœŸ
            save_name=f'{user_graph_save_name}_{current_date.strftime("%Y-%m-%d")}',  # ä¿å­˜åç§°
            save=True,  # ä¿å­˜å›¾æ–‡ä»¶
        )
        print(
            f"ç”¨æˆ·å…³ç³»å›¾å±æ€§: {current_user_graph.number_of_nodes()} ä¸ªèŠ‚ç‚¹, {current_user_graph.number_of_edges()} æ¡è¾¹"
        )

        # æ ¹æ®èŠ‚ç‚¹åº¦æ•°è·å–é¡¶çº§ç”¨æˆ·åˆ—è¡¨
        top_user = get_top_n_users_by_degree(
            G=current_user_graph, top_n=int(node * top_n_user)
        )

        # ============================ å¹¶å‘å¤„ç†ç”¨æˆ·è¾“å…¥ ============================
        print(f"å¼€å§‹å¤„ç† {len(all_user)} ä¸ªç”¨æˆ·ï¼Œä½¿ç”¨ {max_workers} ä¸ªå·¥ä½œçº¿ç¨‹...")

        # åˆå§‹åŒ–ç»“æœå­˜å‚¨åˆ—è¡¨
        results = []  # äº¤æ˜“å†³ç­–ç»“æœ
        forum_args_list = []  # è®ºå›äº’åŠ¨å‚æ•°
        post_args_list = []  # å¸–å­å‘å¸ƒå‚æ•°

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†æ‰€æœ‰ç”¨æˆ·
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ä¸ºæ¯ä¸ªç”¨æˆ·åˆ›å»ºå¹¶å‘ä»»åŠ¡
            futures = [
                executor.submit(
                    process_user_input,
                    user_id,
                    user_db,
                    forum_db,
                    df_stock,
                    current_date,
                    debug,
                    day_1st,
                    current_user_graph,
                    import_news,
                    df_strategy,
                    is_trading_day,
                    top_user,
                    log_dir,
                    prob_of_technical,
                    user_config_mapping,
                    activate_maapping,
                    belief_args,
                    user_config_mapping[user_id],  # ä¼ å…¥ç”¨æˆ·å¯¹åº”çš„é…ç½®
                )
                for user_id in all_user
            ]

            # ä½¿ç”¨tqdmæ˜¾ç¤ºå¤„ç†è¿›åº¦
            for future in tqdm(
                as_completed(futures),
                total=len(all_user),
                desc=f"å¤„ç†è¾“å…¥ {current_date.strftime('%Y-%m-%d')}",
                unit="ç”¨æˆ·",
            ):
                try:
                    # ç­‰å¾…ä»»åŠ¡å®Œæˆï¼Œè®¾ç½®è¶…æ—¶é™åˆ¶
                    user_id, forum_args, decision_result, post_response_args = (
                        future.result(timeout=TIMEOUT_THRESHOLD)
                    )
                    # æ”¶é›†å„ç±»å¤„ç†ç»“æœ
                    forum_args_list.append((user_id, forum_args))
                    results.append((user_id, decision_result))
                    post_args_list.append((user_id, post_response_args))

                except TimeoutError:
                    # è¶…æ—¶å¤„ç†ï¼šä½¿ç”¨åŸå§‹é…ç½®é‡è¯•ï¼ˆä¿®å¤ï¼šä½¿ç”¨ä¼ å…¥çš„ config_path è€Œä¸æ˜¯ç¡¬ç¼–ç  api.yamlï¼‰
                    print(
                        f"[è¾“å…¥å¤„ç†] ç”¨æˆ· {user_id} è¶…æ—¶: å¤„ç†è¶…è¿‡ {TIMEOUT_THRESHOLD//60} åˆ†é’Ÿã€‚ä½¿ç”¨åŸå§‹é…ç½®é‡è¯•..."
                    )
                    fallback_config_path = config_path  # ä½¿ç”¨ä¼ å…¥çš„é…ç½®è·¯å¾„ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç  api.yaml
                    retry_future = executor.submit(
                        process_user_input,
                        user_id,
                        user_db,
                        forum_db,
                        df_stock,
                        current_date,
                        debug,
                        day_1st,
                        current_user_graph,
                        import_news,
                        df_strategy,
                        is_trading_day,
                        top_user,
                        log_dir,
                        prob_of_technical,
                        user_config_mapping,
                        activate_maapping,
                        belief_args,
                        fallback_config_path,
                    )
                    try:
                        # é‡è¯•ä»»åŠ¡çš„ç»“æœå¤„ç†
                        user_id, forum_args, decision_result, post_response_args = (
                            retry_future.result(timeout=TIMEOUT_THRESHOLD)
                        )
                        forum_args_list.append((user_id, forum_args))
                        results.append((user_id, decision_result))
                        post_args_list.append((user_id, post_response_args))
                    except Exception as e:
                        print(f"[è¾“å…¥å¤„ç†] é‡è¯•åä»å¤±è´¥ï¼Œç”¨æˆ· {user_id}: {e}")

                except Exception as e:
                    # å…¶ä»–å¼‚å¸¸å¤„ç†
                    print(f"[è¾“å…¥å¤„ç†] å¤„ç†ç”¨æˆ· {user_id} æ—¶å‡ºé”™: {e}")

        # ============================ ç»“æœæ–‡ä»¶ä¿å­˜ ============================
        # ä¿å­˜äº¤æ˜“å†³ç­–ç»“æœ
        result_dir = os.path.join(f"{log_dir}/trading_records")
        os.makedirs(result_dir, exist_ok=True)
        result_file = os.path.join(
            result_dir, f"{current_date.strftime('%Y-%m-%d')}.json"
        )
        with open(result_file, "w", encoding="utf-8") as f:
            result_dict = {user_id: result for user_id, result in results}
            json.dump(result_dict, f, indent=4, ensure_ascii=False)

        # ä¿å­˜è®ºå›ååº”è®°å½•
        reaction_result_dir = os.path.join(f"{log_dir}/reaction_records")
        os.makedirs(reaction_result_dir, exist_ok=True)
        reaction_result_file = os.path.join(
            reaction_result_dir, f"{current_date.strftime('%Y-%m-%d')}.json"
        )
        with open(reaction_result_file, "w", encoding="utf-8") as f:
            reaction_result_dict = {
                user_id: reaction_result for user_id, reaction_result in forum_args_list
            }
            json.dump(reaction_result_dict, f, indent=4, ensure_ascii=False)

        # ä¿å­˜å¸–å­å‘å¸ƒè®°å½•
        post_result_dir = os.path.join(f"{log_dir}/post_records")
        os.makedirs(post_result_dir, exist_ok=True)
        post_result_file = os.path.join(
            post_result_dir, f"{current_date.strftime('%Y-%m-%d')}.json"
        )
        with open(post_result_file, "w", encoding="utf-8") as f:
            post_result_dict = {
                user_id: post_result for user_id, post_result in post_args_list
            }
            json.dump(post_result_dict, f, indent=4, ensure_ascii=False)

        # ============================ è®ºå›å¸–å­å¤„ç† ============================
        # ç»Ÿè®¡æˆåŠŸåˆ›å»ºçš„å¸–å­æ•°é‡
        successful_posts = 0
        if post_args_list:
            print(f"å¼€å§‹å¤„ç† {len(post_args_list)} ä¸ªç”¨æˆ·çš„å¸–å­å‘å¸ƒ...")
            for user_id, post_response_args in post_args_list:
                try:
                    # æœªæ¿€æ´»ç”¨æˆ·ï¼šä»…æç¤ºä¸€æ¬¡ INFOï¼Œå¹¶è·³è¿‡
                    if not activate_maapping.get(user_id, True):
                        logging.info(f"[inactive] ç”¨æˆ· {user_id} æœªæ¿€æ´»ï¼Œè·³è¿‡å‘å¸–")
                        continue

                    # è·³è¿‡æ— æ•ˆçš„å¸–å­å“åº”ï¼ˆæœªæ¿€æ´»ç”¨æˆ·æˆ–ä¸Šæ¸¸å‡ºé”™ï¼‰
                    if not isinstance(post_response_args, dict):
                        continue

                    required_keys = ("post", "type", "belief")
                    if not all(
                        k in post_response_args and post_response_args[k] is not None
                        for k in required_keys
                    ):
                        continue

                    # åœ¨è®ºå›æ•°æ®åº“ä¸­åˆ›å»ºæ–°å¸–å­
                    create_post_db(
                        user_id=user_id,
                        content=post_response_args["post"],  # å¸–å­å†…å®¹
                        type=post_response_args["type"],  # å¸–å­ç±»å‹
                        belief=str(post_response_args["belief"]),  # ç”¨æˆ·ä¿¡å¿µå€¼
                        created_at=current_date,  # åˆ›å»ºæ—¶é—´
                        db_path=forum_db,  # è®ºå›æ•°æ®åº“è·¯å¾„
                    )
                    successful_posts += 1
                except Exception as e:
                    print(f"[å¸–å­å¤„ç†] ç”¨æˆ· {user_id} å¸–å­åˆ›å»ºå¤±è´¥: {e}")

            print(f"æˆåŠŸå¤„ç† {successful_posts}/{len(post_args_list)} ä¸ªç”¨æˆ·çš„å¸–å­å‘å¸ƒ")

        # ============================ äº¤æ˜“ç³»ç»Ÿæ›´æ–° ============================
        # æ ¹æ®æ˜¯å¦ä¸ºäº¤æ˜“æ—¥é€‰æ‹©ä¸åŒçš„æ›´æ–°ç­–ç•¥
        if is_trading_day:
            # äº¤æ˜“æ—¥ï¼šè¿è¡Œäº¤æ˜“åŒ¹é…ç³»ç»Ÿï¼Œå¤„ç†æ‰€æœ‰äº¤æ˜“è¯·æ±‚
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨è‡ªåŠ¨ç”Ÿæˆå¯¹æ‰‹ç›˜ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
            auto_generate_counterparty = os.getenv("AUTO_GENERATE_COUNTERPARTY", "false").lower() in ("true", "1", "yes")
            test_matching_system(
                current_date=current_date.strftime("%Y-%m-%d"),
                base_path=log_dir,
                db_path=user_db,
                json_file_path=f"{log_dir}/trading_records/{current_date.strftime('%Y-%m-%d')}.json",
                auto_generate_counterparty=auto_generate_counterparty,
            )
        else:
            # éäº¤æ˜“æ—¥ï¼šä»…æ›´æ–°ç”¨æˆ·èµ„æ–™è¡¨ï¼ˆä¸å¤„ç†äº¤æ˜“ï¼‰
            update_profiles_table_holiday(
                current_date=current_date.strftime("%Y-%m-%d"), db_path=user_db
            )

        # ============================ è®ºå›äº’åŠ¨å¤„ç† ============================
        if not day_1st:
            # éç¬¬ä¸€å¤©ï¼šå¤„ç†ç”¨æˆ·åœ¨è®ºå›ä¸­çš„äº’åŠ¨è¡Œä¸º
            successful_actions = 0
            print(f"å¼€å§‹å¤„ç† {len(forum_args_list)} ä¸ªç”¨æˆ·çš„è®ºå›äº’åŠ¨...")

            if forum_args_list:
                for user_id, forum_args in forum_args_list:
                    try:
                        # æ£€æŸ¥è®ºå›å‚æ•°æ˜¯å¦æœ‰æ•ˆ
                        if not isinstance(forum_args, (list, dict)):
                            print(
                                f"[è®ºå›äº’åŠ¨] ç”¨æˆ· {user_id} çš„è®ºå›å‚æ•°ç±»å‹é”™è¯¯: {type(forum_args)}, å€¼: {forum_args}"
                            )
                            continue
                        
                        # å¦‚æœ forum_args æ˜¯å­—å…¸ä¸”åŒ…å« errorï¼Œè·³è¿‡
                        if isinstance(forum_args, dict) and "error" in forum_args:
                            continue
                        
                        # ç¡®ä¿ forum_args æ˜¯åˆ—è¡¨ï¼ˆexecute_forum_actions æœŸæœ› List[Dict]ï¼‰
                        if isinstance(forum_args, dict):
                            # å¦‚æœæ˜¯å­—å…¸ä½†ä¸æ˜¯é”™è¯¯ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
                            forum_args = [forum_args] if forum_args else []
                        elif not isinstance(forum_args, list):
                            forum_args = []

                        # å¼‚æ­¥æ‰§è¡Œè®ºå›äº’åŠ¨æ“ä½œï¼ˆç‚¹èµã€è¯„è®ºç­‰ï¼‰
                        if forum_args:  # åªæœ‰å½“ forum_args ä¸ä¸ºç©ºæ—¶æ‰æ‰§è¡Œ
                            asyncio.run(
                                execute_forum_actions(
                                    forum_args=forum_args,
                                    db_path=forum_db,
                                    user_id=user_id,
                                    created_at=current_date,
                                )
                            )
                        successful_actions += 1
                    except Exception as e:
                        error_msg = str(e)
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ç±»å‹é”™è¯¯ï¼ˆstr object has no attribute 'get'ï¼‰
                        if "'str' object has no attribute 'get'" in error_msg:
                            print(f"[è®ºå›äº’åŠ¨] ç”¨æˆ· {user_id} å¤„ç†å¤±è´¥: forum_argsç±»å‹é”™è¯¯ï¼ˆæœŸæœ›dictæˆ–listï¼Œå®é™…ä¸º{type(forum_args).__name__}ï¼‰: {forum_args}")
                        else:
                            print(f"[è®ºå›äº’åŠ¨] ç”¨æˆ· {user_id} å¤„ç†å¤±è´¥: {e}")

            print(
                f"æˆåŠŸå¤„ç† {successful_actions}/{len(forum_args_list)} ä¸ªç”¨æˆ·çš„è®ºå›äº’åŠ¨"
            )

            # æ›´æ–°è®ºå›å¸–å­çš„è¯„åˆ†ï¼ˆåŸºäºäº’åŠ¨æ•°æ®ï¼‰
            update_posts_score_by_date_range(
                db_path=forum_db, end_date=current_date.strftime("%Y-%m-%d")
            )

        # æ—¥æœŸé€’å¢ï¼Œè¿›å…¥ä¸‹ä¸€å¤©çš„æ¨¡æ‹Ÿ
        current_date += timedelta(days=1)


def parse_args():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œé…ç½®æ¨¡æ‹Ÿç³»ç»Ÿçš„å„ç§å‚æ•°

    Returns:
        argparse.Namespace: åŒ…å«æ‰€æœ‰é…ç½®å‚æ•°çš„å‘½åç©ºé—´å¯¹è±¡
    """
    parser = argparse.ArgumentParser(description="åˆå§‹åŒ–å¹¶è¿è¡Œè‚¡ç¥¨äº¤æ˜“æ¨¡æ‹Ÿç³»ç»Ÿ")

    # ============================ æ—¶é—´èŒƒå›´é…ç½® ============================
    parser.add_argument(
        "--start_date",
        type=str,
        default="2023-06-15",
        help="æ¨¡æ‹Ÿå¼€å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)",
    )
    parser.add_argument(
        "--end_date",
        type=str,
        default="2023-12-15",
        help="æ¨¡æ‹Ÿç»“æŸæ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)",
    )

    # ============================ æ•°æ®åº“é…ç½® ============================
    parser.add_argument(
        "--forum_db",
        type=str,
        default=None,
        help="è®ºå›æ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šresults/{log_dir}/forum_100.dbï¼‰",
    )
    parser.add_argument(
        "--user_db",
        type=str,
        default=None,
        help="ç”¨æˆ·æ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šresults/{log_dir}/user_100.dbï¼‰",
    )

    # ============================ è¿è¡Œé…ç½® ============================
    parser.add_argument("--debug", type=bool, default=False, help="æ˜¯å¦å¼€å¯è°ƒè¯•æ¨¡å¼")
    parser.add_argument(
        "--max_workers", type=int, default=50, help="å¹¶å‘å¤„ç†çš„æœ€å¤§çº¿ç¨‹æ•°"
    )
    parser.add_argument(
        "--log_dir", type=str, default="logs_100_0128_claude", help="æ—¥å¿—æ–‡ä»¶ä¿å­˜ç›®å½•ï¼ˆå°†è‡ªåŠ¨æ”¾åœ¨ results/ ä¸‹ï¼‰"
    )

    # ============================ ç”¨æˆ·å…³ç³»å›¾é…ç½® ============================
    parser.add_argument(
        "--user_graph_save_name",
        type=str,
        default="user_graph_logs_100_0128_claude",
        help="ç”¨æˆ·å…³ç³»å›¾ä¿å­˜æ–‡ä»¶åç§°",
    )
    parser.add_argument(
        "--similarity_threshold",
        type=float,
        default=0.2,
        help="æ„å»ºç”¨æˆ·å…³ç³»å›¾çš„ç›¸ä¼¼åº¦é˜ˆå€¼",
    )
    parser.add_argument(
        "--time_decay_factor",
        type=float,
        default=0.5,
        help="æ„å»ºç”¨æˆ·å…³ç³»å›¾çš„æ—¶é—´è¡°å‡å› å­",
    )
    parser.add_argument("--node", type=int, default=100, help="ç”¨æˆ·å…³ç³»å›¾ä¸­çš„èŠ‚ç‚¹æ•°é‡")
    parser.add_argument(
        "--top_n_user", type=float, default=0.1, help="é¡¶çº§ç”¨æˆ·æ‰€å æ¯”ä¾‹"
    )

    # ============================ äº¤æ˜“è¡Œä¸ºé…ç½® ============================
    parser.add_argument(
        "--prob_of_technical",
        type=float,
        default=0.5,
        help="æŠ€æœ¯é¢å™ªå£°äº¤æ˜“è€…çš„æ¿€æ´»æ¦‚ç‡",
    )
    parser.add_argument(
        "--activate_prob", type=float, default=1.0, help="ç”¨æˆ·æ¿€æ´»å‚ä¸æ¨¡æ‹Ÿçš„æ¦‚ç‡"
    )

    # ============================ æ•°æ®æ–‡ä»¶é…ç½® ============================
    parser.add_argument(
        "--belief_init_path",
        type=str,
        default="util/belief/belief_1000_0129.csv",
        help="ç”¨æˆ·åˆå§‹ä¿¡å¿µå€¼æ–‡ä»¶è·¯å¾„",
    )
    parser.add_argument(
        "--config_path", type=str, default="./config/api.yaml", help="APIé…ç½®æ–‡ä»¶è·¯å¾„"
    )

    return parser.parse_args()


if __name__ == "__main__":
    """
    ä¸»ç¨‹åºå…¥å£ï¼šè§£æå‚æ•°å¹¶å¯åŠ¨æ¨¡æ‹Ÿç³»ç»Ÿ
    """

    # ============================ å‚æ•°è§£æä¸éªŒè¯ ============================
    args = parse_args()

    # å°†è¾“å‡ºç›®å½•æ”¹ä¸º results/{log_dir} ç»“æ„
    original_log_dir = args.log_dir
    args.log_dir = os.path.join("results", original_log_dir)
    
    # ç¡®ä¿ results ç›®å½•å’Œæ—¥å¿—ç›®å½•å­˜åœ¨
    os.makedirs("results", exist_ok=True)
    if not os.path.exists(args.log_dir):
        os.makedirs(args.log_dir)
        print(f"åˆ›å»ºæ—¥å¿—ç›®å½•: {args.log_dir}")

    # è¾“å‡ºæ‰€æœ‰é…ç½®å‚æ•°
    print("\n=== æ¨¡æ‹Ÿé…ç½®å‚æ•° ===")
    print(json.dumps(vars(args), indent=4, ensure_ascii=False))

    # ============================ æ£€æŸ¥ç‚¹é€»è¾‘åˆ¤æ–­ ============================
    # è‡ªåŠ¨æ£€æµ‹æœ€åä¸€ä¸ªæˆåŠŸå¤„ç†çš„æ—¥æœŸï¼ˆé€šè¿‡æ£€æŸ¥trading_recordsç›®å½•ï¼‰
    def find_last_completed_date(log_dir, start_date, end_date):
        """æŸ¥æ‰¾æœ€åä¸€ä¸ªæˆåŠŸå¤„ç†çš„æ—¥æœŸ"""
        trading_records_dir = os.path.join(log_dir, "trading_records")
        if not os.path.exists(trading_records_dir):
            return None
        
        # è·å–æ‰€æœ‰å·²å¤„ç†çš„æ—¥æœŸæ–‡ä»¶
        completed_dates = []
        for filename in os.listdir(trading_records_dir):
            if filename.endswith(".json") and filename.startswith("2023-"):
                date_str = filename.replace(".json", "")
                try:
                    date = pd.Timestamp(date_str)
                    if start_date <= date <= end_date:
                        completed_dates.append(date)
                except:
                    continue
        
        if completed_dates:
            # æŒ‰æ—¥æœŸæ’åºï¼Œè¿”å›æœ€åä¸€ä¸ª
            completed_dates.sort()
            return completed_dates[-1]
        return None
    
    # æ£€æŸ¥æ˜¯å¦è¦è‡ªåŠ¨ä»æ–­ç‚¹æ¢å¤
    original_start_date = pd.Timestamp(args.start_date)
    original_end_date = pd.Timestamp(args.end_date)
    last_completed_date = find_last_completed_date(args.log_dir, original_start_date, original_end_date)
    
    # å¦‚æœæ‰¾åˆ°äº†æœ€åå®Œæˆçš„æ—¥æœŸï¼Œä¸”è¯¥æ—¥æœŸå°äºç»“æŸæ—¥æœŸï¼Œåˆ™ä»ä¸‹ä¸€å¤©ç»§ç»­
    if last_completed_date is not None and last_completed_date < original_end_date:
        # ä»æœ€åå®Œæˆæ—¥æœŸçš„ä¸‹ä¸€å¤©ç»§ç»­
        resume_date = last_completed_date + pd.Timedelta(days=1)
        args.start_date = resume_date.strftime("%Y-%m-%d")
        checkpoint = True
        print(f"âœ… æ£€æµ‹åˆ°å·²æœ‰å¤„ç†è®°å½•ï¼Œæœ€åå®Œæˆæ—¥æœŸ: {last_completed_date.strftime('%Y-%m-%d')}")
        print(f"ğŸ“… å°†ä» {args.start_date} ç»§ç»­è¿è¡Œåˆ° {args.end_date}")
        print(f"æ¨¡å¼: ä»æ£€æŸ¥ç‚¹ {args.start_date} ç»§ç»­æ¨¡æ‹Ÿ")
    elif args.start_date == "2023-06-15":
        checkpoint = False  # ä»å¤´å¼€å§‹ï¼Œéœ€è¦åˆå§‹åŒ–æ‰€æœ‰æ•°æ®
        print("æ¨¡å¼: ä»å¤´å¼€å§‹æ¨¡æ‹Ÿ")
    else:
        checkpoint = True  # ä»æŒ‡å®šçš„å¼€å§‹æ—¥æœŸç»§ç»­
        print(f"æ¨¡å¼: ä»æ£€æŸ¥ç‚¹ {args.start_date} ç»§ç»­æ¨¡æ‹Ÿ")

    # ============================ æ•°æ®åº“è·¯å¾„è®¾ç½® ============================
    # å¦‚æœæœªæŒ‡å®šæ•°æ®åº“è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„ï¼ˆåœ¨ results/{log_dir} ä¸‹ï¼‰
    if args.forum_db is None:
        args.forum_db = os.path.join(args.log_dir, "forum_100.db")
    if args.user_db is None:
        args.user_db = os.path.join(args.log_dir, "user_100.db")
    
    # ============================ æ•°æ®åº“åˆå§‹åŒ– ============================
    if not checkpoint:
        print("åˆå§‹åŒ–è®ºå›æ•°æ®åº“...")
        init_db_forum(db_path=args.forum_db)
        print("è®ºå›æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

    # ============================ å¯åŠ¨æ¨¡æ‹Ÿç³»ç»Ÿ ============================
    print("\n=== å¼€å§‹è¿è¡Œäº¤æ˜“æ¨¡æ‹Ÿç³»ç»Ÿ ===")
    init_simulation(
        start_date=pd.Timestamp(args.start_date),
        end_date=pd.Timestamp(args.end_date),
        forum_db=args.forum_db,
        user_db=args.user_db,
        debug=args.debug,
        max_workers=args.max_workers,
        user_graph_save_name=args.user_graph_save_name,
        checkpoint=checkpoint,
        similarity_threshold=args.similarity_threshold,
        time_decay_factor=args.time_decay_factor,
        node=args.node,
        log_dir=args.log_dir,
        prob_of_technical=args.prob_of_technical,
        belief_init_path=args.belief_init_path,
        config_path=args.config_path,
        activate_prob=args.activate_prob,
    )
    print("\n=== æ¨¡æ‹Ÿç³»ç»Ÿè¿è¡Œå®Œæˆ ===")
